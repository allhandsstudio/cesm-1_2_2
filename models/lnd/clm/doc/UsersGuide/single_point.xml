
<!-- Beg of single_point chapter-->
<chapter id="single_point">
<title>How to run Single-Point/Regional cases</title>
<para>
The &clm; also allows you to set up and run cases with a single-point or a local region as well
as global resolutions. This is often useful for running quick cases for testing, evaluating
specific vegetation types, or land-units, or running with observed data for a specific site.
There are three different ways to do this: normal-supported site, &PTSMODE;,
&CLMUSRDAT;, and with &ptclm;.
<simplelist>
<member><emphasis>normal supported site</emphasis> -- to run for a supported single point
or regional dataset.</member>
<member><emphasis>&PTSMODE;</emphasis> -- to run for a single point
using global datasets.</member>
<member><emphasis>&CLMUSRDAT;</emphasis> -- to run using your own datasets (single-point
or regional).</member>
<member><emphasis>&ptclm;</emphasis> -\- to easily setup simulations to run for
tower sites..</member>
</simplelist>
</para>
<note>
<para>
&PTSMODE; and &ptclm; only works for a single point, while the other two options can
also work for regional datasets as well.
</para>
</note>
<sect1 id="which_singlept_option">
<title>Which Single Point Option Should I choose?</title>
<para>
Running for a <emphasis>normal supported site</emphasis> is a great solution, if one of the supported
single-point/regional datasets, is your region of interest (see 
<xref linkend="suprted_single_point_datasets"></xref>). All the datasets are 
created for you, and you can easily select one and run, out of the box with it using
a supported resolution from the top level of the &cesm; scripts. The problem is that 
there is a very limited set of supported datasets. You 
can also use this method for your own datasets, but you have to create the datasets, 
and add them to the XML database in scripts, &clm; and to the &datm;. This is worthwhile if you want to 
repeat many multiple cases for a given point or region.
</para>
<para>
In general <xref linkend="PTS_MODE"></xref> is the quick and dirty method 
that gets you started without having to create datasets -- but has limitations. It's 
good for an initial attempt at seeing results for a point of interest, but since you 
can NOT restart with it, it's usage is limited. It is the quickest method as you can
create a case for it directly from <command>create_newcase</command>. Although you
can't restart, running a single point is very fast, and you can run for long 
simulation times even without restarts. 
<!--
If you need restarts a good solution is to use 
<command>getregional_datasets.pl</command> and <emphasis>&CLMUSRDAT;</emphasis> 
which can get you running almost as quickly as well as 
<emphasis>&PTSMODE;</emphasis>. Like 
<emphasis>&PTSMODE;</emphasis> 
<xref linkend="getregional_datasets.pl"></xref> only runs for points that exist within 
a global dataset.
-->
</para>
<para>
Next, <emphasis>&CLMUSRDAT;</emphasis> is the best way to setup cases quickly
where you have to create your own datasets (see 
<xref linkend="own_single_point_datasets"></xref>). With this method you don't have to
change &datm; or add files to the XML database -- but you have to follow a strict 
naming convention for files. However, once the files are named and in the proper
location, you can easily setup new cases that use these datasets. This is good
for treating all the required datasets as a "group" and for a particular 
model version. For advanced &clm; developers who need to track dataset changes with 
different model versions you would be best off adding these datasets as supported
datasets with the "normal supported datasets" method.
</para>
<para>
Lastly <emphasis>&ptclm;</emphasis> is a great way to easily create datasets, 
setup simulations and run simulations for tower sites. It takes advantage of both
normal supported site functionality and &CLMUSRDAT; internally. A big advantage to it, is that it's one-stop
shopping, it runs tools to create datasets, and runs <command>create_newcase</command>
and sets the appropriate env variables for you. So you only have to learn how to run
one tool, rather than work with many different ones. &ptclm; is described in the next
chapter <xref linkend="PTCLMDOC"></xref>.
</para>
<para>
Finally, if you also have meteorology data that you want to force your &clm; simulations
with you'll need to setup cases as described in <xref linkend="own_atm_forcing"></xref>.
You'll need to create &clm; datasets either according to 
<emphasis>&CLMUSRDAT;</emphasis>. You may also need to modify &datm; to use
your forcing data. And you'll need to change your forcing data to be in a format that
&datm; can use. 
In the &ptclm; chapter the <xref linkend="AmeriFluxdata"></xref> 
section tells you how to use AmeriFlux data for atmospheric forcing.
</para>
</sect1>

<sect1 id="PTS_MODE">
<title>Running &PTSMODE; configurations</title>
<para>
&PTSMODE; enables you to run the model using global datasets, but just picking a
single point from those datasets and operating on it. It can be a very quick way to do fast
simulations and get a quick turnaround.
</para>
<para>
To setup a &PTSMODE; simulation you use the "-pts_lat" and "-pts_lon"
arguments to <command>create_newcase</command> to give the latitude and longitude of the point you want to
simulate for (the code will pick the point on the global grid nearest to the point you
give. Here's an example to setup a simulation for the nearest point at 2-degree resolution
to Boulder Colorado.
<screen width="99">
> cd scripts
> ./create_newcase -case testPTS_MODE -res f19_g16 -compset I1850CRUCLM45BGC -mach yellowstone_intel \
-pts_lat 40.0 -pts_lon -105
> cd testPTS_MODE
# We make sure the model will start up cold rather than using initial conditions
> ./xmlchange &CLMFORCECOLD;=on,RUN_TYPE=startup
</screen>
Then setup, build and run as normal. We make sure initial conditions are NOT used
since &PTSMODE; currently CAN NOT run with initial conditions.
</para>
<note>
<para>
This works the same for &clm40; and &clm45;.
</para>
</note>
<important>
<para>
By default it sets up to run with
<envar>MPILIB=mpi-serial</envar> (in the <filename>env_build.xml</filename> file) turned on, 
which allows you to run the model interactively. On some machines this mode is NOT 
supported and you may need to change it to FALSE before you are able to build.
</para>
</important>
<warning>
<para>
&PTSMODE; currently does <emphasis>NOT</emphasis> restart nor
is it able to startup from global initial condition files. See bugs "1017 and 1025"
in the &KnownLims; file.
</para>
</warning>
<note>
<para>
You can change the point you are simulating for at run-time by changing the values of
<envar>PTS_LAT</envar> and <envar>PTS_LON</envar> in the <filename>env_run.xml</filename> file.
</para>
</note>
<note>
<para>
Note, that when running with &PTSMODE; the number of processors
is automatically set to one. When running a single grid point you can only use a single
processor. You might also want to set the &envbuild; variable: <envar>MPILIB=mpi-serial</envar> to
<literal>TRUE</literal> so that you can also run interactively without having to use
&mpi; to start up your job.
</para>
</note>
</sect1>
<sect1 id="share_que">
<title>Warning about Running with a Single-Processor on a Batch Machine</title>
<para>
This problem always comes up when running for a single point, because you can only use
a single-processor, but may come up in other instances when you are running with
one processor. This applies to all the different ways of running in single-point mode.
</para>
<note>
<para>
On many machines is that some batch ques have a minimum number 
of nodes or processors that can be used. On these machines you may have to change the
queue and possibly the time-limits of the job, to get it to run in the batch queue.
On yellowstone this is done for you automatically, and the "caldera" queue is used
for such single-processor simulations.
</para>
</note>
<para>
Another way to get around this problem is to run the job interactively using
<envar>MPILIB=mpi-serial</envar> so that you don't submit the job to the batch queue.
For single point mode you also may want to consider using a smaller workstation or
cluster, rather than a super-computer, because you can't take advantage of the
multi-processing power of the super-computer anyway.
</para>
</sect1>

<sect1 id="suprted_single_point_datasets">
<title>Running Supported Single-point/Regional Datasets</title>
<para>
In addition to &PTSMODE; the &clm; supports running using single-point or
regional datasets that are customized to a particular region. In the section below we
tell the user how to create their own dataset, but we also support a small number of
single-point and regional datasets that are ready to setup and run in the CESM modeling
system.
</para>
<para>
To get the list of supported dataset resolutions do this:
<screen width="99">
> cd models/lnd/clm/doc
> ../bld/&buildnml; -res list
</screen>
Which results in the following:
<screen width="99">
&res_list;
</screen>
The resolution names that have an underscore in them ("_") are all single-point or 
regional resolutions.
</para>
<para>
To run for the Brazil test site
do the following:
<example id="brazil_1x1">
<title>Example of running &clm; over a single-point test site in Brazil
with the default Qian atmosphere data forcing.
</title>
<screen width="99">
> cd scripts
> set SITE=1x1_brazil
> ./create_newcase -case testSPDATASET -res $SITE -compset I \
-mach yellowstone_intel
> cd testSPDATASET
</screen>
</example>
</para>
<para>
Then setup, build and run normally.
</para>
<para>
Then to run for the urban Mexico City Mexico test site that also has atmosphere
forcing data, but to run it with the Qian forcing data, but over the period for
which it's own forcing data is provided do the following:
<example id="mexicocity">
<title>Example of running &clm; over the single-point of Mexicocity Mexico
with the default Qian atmosphere data forcing.
</title>
<screen width="99">
> cd scripts
# Set a variable to the site you want to use (as it's used several times below)
> set SITE=1x1_mexicocityMEX
> ./create_newcase -case testSPDATASET -res $SITE -compset I \
-mach yellowstone_intel
> cd testSPDATASET
# Set &datm; prescribed aerosols to single-point dataset
# Will then use the dataset with just the point for this $SITE
> ./xmlchange DATM_PRESAERO=pt1_pt1
</screen>
</example>
</para>
<para>
Then setup, build and run normally.
</para>
<important>
<para>
Just like &PTSMODE; above, By default it sets up to run with
<envar>MPILIB=mpi-serial</envar> (in the <filename>env_build.xml</filename> file) turned on, 
which allows you to run the model interactively. On some machines this mode is NOT 
supported and you may need to change it to FALSE before you are able to build.
</para>
</important>
<warning>
<para>
See <xref linkend="share_que"></xref> for a warning about running single-point jobs
on batch machines.
</para>
</warning>
<note>
<para>
Note, that when running a <literal>pt1_pt1</literal> resolution the number of processors
is automatically set to one. When running a single grid point you can only use a single
processor. You might also want to set the &envbuild; variable: <envar>MPILIB=mpi-serial</envar> to
<literal>TRUE</literal> so that you can also run interactively without having to use
MPI to start up your job.
</para>
</note>
<sect2 id="sp_atm_forcing">
<title>Running Supported Single-point Datasets that have their own Atmospheric Forcing</title>
<para>
Of the supported single-point datasets we have three that also have atmospheric forcing data 
that go with them: Mexico City (Mexico), Vancouver, (Canada, British Columbia), and
urbanc_alpha (test data for an Urban inter-comparison project). Mexico city and Vancouver
also have "#ifdef" in the source code for them to work with modified urban data
parameters that are particular to these locations. They can be turned on by using
the &CLMCONFIG; &envbuild; variable to set the "-sitespf_pt" option in the &clm;
&configure;. To turn on the atmospheric forcing for these datasets, you set the
&envrun; <envar>DATM_MODE</envar> variable to &CLM1PT;, and then the atmospheric
forcing datasets will be used for the point picked. 
</para>
<para>
When running with datasets that have their own atmospheric forcing you need to be careful
to run over the period that data is available. If you have at least one year of forcing
it will cycle over the available data over and over again no matter how long of a simulation
you run. However, if you have less than a years worth of data (or if the start date doesn't
start at the beginning of the year, or the end date doesn't end at the end of the year) then
you won't be able to run over anything but the data extent. In this case you will need to 
carefully set the <envar>RUN_STARTDATE</envar>, <envar>START_TOD</envar> and 
<envar>STOP_N/STOP_OPTION</envar> variables for your case to run over the entire time extent 
of your data. For the supported data points, these values are in the XML database
and you can use the <command>queryDefaultNamelist.pl</command> script to query the values
and set them for your case (they are set for the three urban test cases: Mexicocity, Vancouver, and
urbanc_alpha).
</para>
<para>
In the example below we will show how to do this for the Vancouver, Canada point.
</para>
<example id="vancouver">
<title>Example of running &clm; over the single-point of Vancouver Canada with 
supplied atmospheric forcing data for Vancouver.
</title>
<screen width="99">
> cd scripts
# Set a variable to the site you want to use (as it's used several times below)
> set SITE=1x1_vancouverCAN
# Create a case at the single-point resolutions with their forcing
> ./create_newcase -case testSPDATASETnAtmForcing -res $SITE -compset I1PTCLM45 \
-mach yellowstone_intel
> cd testSPDATASETnAtmForcing
# Set namelist options for urban test site
> ./xmlchange CLM_NML_USE_CASE=stdurbpt_pd
# Figure out the start and end date for this dataset
# You can do this by examining the datafile.
> set STOP_N=330
> set START_YEAR=1992
> set STARTDATE=${START_YEAR}-08-12
> @ NDAYS = $STOP_N / 24
> ./xmlchange RUN_STARTDATE=$STARTDATE,STOP_N=$STOP_N,STOP_OPTION=nsteps
# Set the User namelist to set the output frequencies of the history files
# Setting the stdurbpt use-case option create three history file streams
# The frequencies and number of time-samples needs to be set
> cat &lt;&lt; EOF &gt; &usernlclm;
 hist_mfilt = $NDAYS,$STOP_N,$STOP_N
 hist_nhtfrq = -1,1,1
EOF
# Set &datm; prescribed aerosols to single-point dataset
# Will then use the dataset with just the point for this site
> ./xmlchange DATM_PRESAERO=pt1_pt1
> ./cesm_setup
</screen>
</example>
<caution>
<para>
If you don't set the start-year and run-length carefully as shown above the
model will abort with a "dtlimit error" in the atmosphere model (see bug 1110 in
the &KnownLims; file for documentation on this). Since, the forcing data for 
this site (and the MexicoCity site) is less than a year, the model won't be able to 
run for a full year.  The <literal>1x1_urbanc_alpha</literal> site has data for more 
than a full year, but neither year is complete hence, it has the same problem (see the
problem for this site above).
</para>
</caution>
<important>
<para>
Just like &PTSMODE; above, By default it sets up to run with
<envar>MPILIB=mpi-serial</envar> (in the <filename>env_build.xml</filename> file) turned on, 
which allows you to run the model interactively.
</para>
</important>
<warning>
<para>
See <xref linkend="share_que"></xref> for a warning about running single-point jobs
on batch machines.
</para>
</warning>
<note>
<para>
Note, that when running a <literal>pt1_pt1</literal> resolution the number of processors
is automatically set to one. When running a single grid point you can only use a single
processor. You might also want to set the &envbuild; variable: <envar>MPILIB=mpi-serial</envar> to
<literal>TRUE</literal> so that you can also run interactively without having to use
MPI to start up your job.
</para>
</note>
</sect2>
</sect1>

<sect1 id="own_single_point_datasets">
<title>Creating your own single-point/regional surface datasets</title>
<para> 
Here's an example of setting up a case using &CLMUSRDAT; where you rename the files according to
the &CLMUSRDAT; convention. We have an example of such datafiles in the repository for a specific
region over Alaska (actually just a sub-set of the global f19 grid).
</para>
<example id="example_using_clmusrdat">
<title>Example of using &CLMUSRDAT; to run a simulation using user datasets for a
specific region over Alaska</title>
<screen width="99">
> cd scripts
> ./create_newcase -case my_userdataset_test -res CLM_USRDAT -compset ICRUCLM45 \
-mach yellowstone_intel
> cd my_userdataset_test/
> set GRIDNAME=13x12pt_f19_alaskaUSA
> set LMASK=gx1v6
> ./xmlchange CLM_USRDAT_NAME=$GRIDNAME,CLM_BLDNML_OPTS="-mask $LMASK"
> ./xmlchange ATM_DOMAIN_FILE=domain.lnd.${GRIDNAME}_$LMASK.nc
> ./xmlchange LND_DOMAIN_FILE=domain.lnd.${GRIDNAME}_$LMASK.nc
# Make sure the file exists in your $CSMDATA or else use svn to download it there
> ls $CSMDATA/lnd/clm2/surfdata_map/surfdata_${GRIDNAME}_simyr2000.nc
# If it doesn't exist, comment out the following...
#> setenv SVN_INP_URL https://svn-ccsm-inputdata.cgd.ucar.edu/trunk/inputdata/
#> svn export $SVN_INP_URL/lnd/clm2/surfdata_map/surfdata_${GRIDNAME}_simyr2000.nc \
#$CSMDATA/lnd/clm2/surfdata_map/surfdata_${GRIDNAME}_simyr2000.nc
> ./cesm_setup
</screen>
</example>
<para>
The first step is to create the domain and surface datasets using the process outlined in 
<xref linkend="file_creation_process"></xref>. Below we show an example of the process.
<example id="creating_boulderCO_singlept_fsurdat">
<title>Example of creating a surface dataset for a single point</title>
<screen width="99">
# set the GRIDNAME and creation date that will be used later
> setenv GRIDNAME 1x1_boulderCO
> setenv CDATE    `date +%y%m%d`
# Create the &scrip; grid file for the location and create a unity mapping file for it.
> cd models/lnd/clm/tools/shared/mkmapdata
> ./mknoocnmap.pl -p 40,255 -n $GRIDNAME
# Set pointer to MAPFILE just created that will be used later
> setenv MAPFILE `pwd`/map_${GRIDNAME}_noocean_to_${GRIDNAME}_nomask_aave_da_${CDATE}.nc
# create the mapping files needed by <command>mksurfdata_map</command>.
> cd ../../shared/mkmapdata
> setenv GRIDFILE ../mkmapgrids/SCRIPgrid_${GRIDNAME}_nomask_${CDATE}.nc
> ./mkmapdata.sh -r $GRIDNAME -f $GRIDFILE -t regional
# create the domain file
> cd ../../../../tools/mapping/gen_domain_files/src
> ../../../scripts/ccsm_utils/Machines/configure -mach yellowstone -compiler intel
> gmake
> cd ..
> setenv OCNDOM domain.ocn_noocean.nc
> setenv ATMDOM domain.lnd.{$GRIDNAME}_noocean.nc
> ./gen_domain -m $MAPFILE -o $OCNDOM -l $ATMDOM
# Save the location where the domain file was created 
> setenv GENDOM_PATH `pwd`
# Finally create the surface dataset
> cd ../../../../lnd/clm/tools/clm4_5/mksurfdata_map/src
> gmake
> cd ..
> ./mksurfdata.pl -r usrspec -usr_gname $GRIDNAME -usr_gdate $CDATE
</screen>
</example>
</para>
<para>
The next step is to create a case that points to the files you created above. We will still use
the &CLMUSRDAT; option as a way to get a case setup without having to add the grid to scripts.
<example id="setting_up_case_for_own_single_point_datasets">
<title>Example of setting up a case from the single-point surface dataset just created</title>
<screen width="99">
# First setup an environment variable that points to the top of the &cesm; directory.
> setenv CESMROOT &lt;directory-of-path-to-main-cesm-directory&gt;
# Next make sure you have a inputdata location that you can write to 
# You only need to do this step once, so you won't need to do this in the future
> setenv MYCSMDATA $HOME/inputdata     # Set env var for the directory for input data
> ./link_dirtree $CSMDATA $MYCSMDATA
# Copy the file you created above to your new $MYCSMDATA location following the CLMUSRDAT 
# naming convention (leave off the creation date)
> cp $CESMROOT/models/lnd/clm/tools/clm4_5/mksurfdata_map/surfdata_${GRIDNAME}_simyr1850_$CDATE.nc \
$MYCSMDATA/lnd/clm2/surfdata_map/surfdata_${GRIDNAME}_simyr1850.nc
> cd $CESMROOT/scripts
> ./create_newcase -case my_usernldatasets_test -res CLM_USRDAT -compset I1850CRUCLM45BGC \
-mach yellowstone_intel
> cd my_usernldatasets_test
> ./xmlchange DIN_LOC_ROOT=$MYCSMDATA
# Set the path to the location of gen_domain set in the creation step above
> ./xmlchange ATM_DOMAIN_PATH=$GENDOM_PATH,LND_DOMAIN_PATH=$GENDOM_PATH
> ./xmlchange ATM_DOMAIN_FILE=$ATMDOM,LND_DOMAIN_FILE=$ATMDOM
> ./xmlchange CLM_USRDAT_NAME=$GRIDNAME
> ./cesm_setup
</screen>
</example>
</para>
<note>
<para>
With this and previous versions of the model we recommended using &CLMUSRDAT; as a way to identify
your own datasets without having to enter them into the XML database. This has two down-sides.
First you can't include creation dates in your filenames, which means you can't keep
track of different versions by date. It also means you HAVE to rename the files after you
created them with <command>mksurfdata.pl</command>. And secondly, you have to use 
<command>linkdirtree</command> in order to place the files in a location outside of the usual
<envar>DIN_LOC_ROOT</envar> (assuming you don't have write access to adding new files to the
standard location on the machine you are using). Now, since <filename>user_nl</filename> files
are supported for ALL model components, and the same domain files are read by both &clm; and &datm;
and set using the envxml variables: 
<envar>ATM_DOMAIN_PATH</envar>,
<envar>ATM_DOMAIN_FILE</envar>,
<envar>LND_DOMAIN_PATH</envar>, and
<envar>LND_DOMAIN_FILE</envar> -- you can use this mechanism (&usernlclm; and &usernldatm; and those
envxml variables) to point to your datasets in any location. In the future we will deprecate &CLMUSRDAT;
and recommend &usernlclm; and &usernldatm; and the <envar>DOMAIN</envar> envxml variables.
</para>
</note>
</sect1>

<sect1 id="own_atm_forcing">
<title>Running with your own atmosphere forcing</title>
<para>
Here we want to run with our own customized datasets for &clm; as well as 
running with our own supplied atmosphere forcing datasets. Thus we effectively
combine the information from <xref linkend="sp_atm_forcing"></xref> with 
<xref linkend="own_single_point_datasets"></xref>. First we need to follow
the procedures in <xref linkend="sp_atm_forcing"></xref> to come up with &clm;
datasets that are customized for our point or region in question. This includes
running <command>link_dirtree</command> to create a directory location where you
can add your own files to it. Next, set
<envar>DATM_MODE</envar> to &CLM1PT; and &CLMUSRDAT; to the
id of the data you created. To see a list of what the filenames need to be
see the section on setting <link linkend="CLMUSRDAT">&CLMUSRDAT;</link>.
</para>
<para>
Next we need to setup the atmosphere forcing data in &netcdf; format that can be
read by &datm;. There is a list of eight variables that are expected to be on the input
files with the names and units on the following table (in the table TDEW and SHUM
are optional fields that can be used in place of RH). In the table we also list
which of the fields are required and if not required what the code will do to
replace them. If the names of the fields are different or the list is changed
from the standard list of eight fields: FLDS, FSDS, PRECTmms, 
PSRF, RH, TBOT, WIND, and ZBOT, the resulting streams file will need to be modified
to take this into account (see an example streams file for this in <xref
linkend="own_force_streams"></xref> below).
<table id="atm_forcing_fields" tocentry="1" pgwide="1" frame="all">
<title>Atmosphere Forcing Fields</title>
<tgroup cols="4" align="left" colsep="1" rowsep="1">
<thead>
<row>
   <entry><para>Short-name</para></entry>
   <entry><para>Description</para></entry>
   <entry><para>Units</para></entry>
   <entry><para>Required?</para></entry>
   <entry><para>If NOT required how replaced</para></entry>
</row>
</thead>
<tbody>
<row>
   <entry>FLDS</entry><entry>incident longwave
(FLDS)</entry><entry>W/m2</entry><entry>No</entry>
<entry>calculates based on Temperature, Pressure and Humidity (NOTE: The &cru; data includes LW down, but by default we
do NOT use it -- we use the calculated values)</entry>
</row>
<row>
   <entry>FSDS</entry><entry>incident solar
(FSDS)</entry><entry>W/m2</entry><entry>Yes</entry><entry>-</entry>
</row>
<row>
   <entry>FSDSdif</entry><entry>incident solar (FSDS)
diffuse</entry><entry>W/m2</entry><entry>No</entry><entry>based on FSDS</entry>
</row>
<row>
   <entry>FSDSdir</entry><entry>incident solar (FSDS)
direct</entry><entry>W/m2</entry><entry>No</entry><entry>based on FSDS</entry>
</row>
<row>
   <entry>PRECTmms</entry><entry>precipitation
(PRECTmms)</entry><entry>mm/s</entry><entry>Yes</entry><entry>-</entry>
</row>
<row>
   <entry>PSRF</entry><entry>pressure at the lowest atm level
(PSRF)</entry><entry>Pa</entry><entry>No</entry><entry>assumes standard-pressure</entry>
</row>
<row>
   <entry>RH</entry><entry>relative humidity at the lowest atm level
(RH)</entry><entry>%</entry><entry>No</entry><entry>can be replaced with SHUM or TDEW</entry>
</row>
<row>
   <entry>SHUM</entry><entry>specific humidity at the lowest atm level
</entry><entry>kg/kg</entry><entry>Optional in place of RH</entry><entry>can be replaced with RH or TDEW</entry>
</row>
<row>
   <entry>TBOT</entry><entry>temperature at the lowest atm level
(TBOT)</entry><entry>K (or can be C)</entry><entry>Yes</entry><entry>-</entry>
</row>
<row>
   <entry>TDEW</entry><entry>dew point temperature
</entry><entry>K (or can be C)</entry><entry>Optional in place of RH</entry><entry>can be replaced with RH or SHUM</entry>
</row>
<row>
   <entry>WIND</entry><entry>wind at the lowest atm level
(WIND)</entry><entry>m/s</entry><entry>Yes</entry><entry>-</entry>
</row>
<row>
   <entry>ZBOT</entry><entry>observational height</entry><entry>m</entry><entry>No
</entry><entry>assumes 30 meters</entry>
</row>
</tbody>
</tgroup>
</table>
All of the variables should be dimensioned: time, lat, lon, with time being the unlimited
dimension. The coordinate variable "time" is also required with CF-compliant units in
days, hours, minutes, or seconds. It can also have a calendar attribute that can
be "noleap" or "gregorian". Normally the files will be placed in the:
<filename>$MYCSMDATA/atm/datm7/CLM1PT_data/$MYUSRDAT</filename> directory with separate files per
month called <filename>YYYY-MM.nc</filename> where YYYY-MM corresponds to the four
digit year and two digit month with a dash in-between. You also need a domain file that
gives the coordinate information for the data that should be placed in:
<filename>$MYCSMDATA/atm/datm7/domain.lnd.$MYUSRDAT_USGS.nc</filename>.
<example id="own_force">
<title>Example of setting up a case with your own atmosphere forcing</title>
<screen width="99">
> cd scripts
# First make sure you have a inputdata location that you can write to 
# You only need to do this step once, so you won't need to do this in the future
> setenv MYCSMDATA $HOME/inputdata     # Set env var for the directory for input data
> ./link_dirtree $CSMDATA $MYCSMDATA
# Next create and move all your datasets into $MYCSMDATA with id $MYUSRDAT
# See above for naming conventions

#  Now create a single-point case
> ./create_newcase -case my_atmforc_test -res pt1_pt1 -compset I1850CRUCLM45BGC \
-mach yellowstone_intel
> cd my_atmforc_test
# Set the data root to your inputdata directory, and set &CLMUSRDAT; 
# to the user id you created for your datasets above
> ./xmlchange DIN_LOC_ROOT_CSMDATA=$MYCSMDATA,&CLMUSRDAT;=$MYUSRDAT
# Set the land-mask to USGS, so both clm and &datm; can find files
> ./xmlchange &CLMBLDNML;='-mask USGS'
# Then set DATM_MODE to single-point mode so &datm; will use your forcing datasets
# Put your forcing datasets into $MYCSMDATA/atm/datm7/CLM1PT_data/$MYUSRDAT
> ./xmlchange DATM_MODE=CLM1PT
> ./cesm_setup
# If the list of fields, or filenames, filepaths, or fieldnames are different 
# you'll need to edit the &datm; namelist streams file to make it consistent
> $EDITOR Buildconf/datm.buildnml.csh
</screen>
</example>
</para>
<warning>
<para>
See <xref linkend="share_que"></xref> for a warning about running single-point jobs
on batch machines.
</para>
</warning>
<note>
<para>
See <xref linkend="managingyourdata"></xref> for notes about managing your data
when using <command>link_dirtree</command>.
</para>
</note>

<para>
Now, we'll show an example of what the &datm; streams file might look like for a case
with your own forcing data with 3-hourly forcing. In this example, we'll leave off the 
fields: ZBOT, and FLDS so they'll be calculated as given in the 
<xref linkend="atm_forcing_fields"></xref> table above. We'll also include: 
FSDSdif and FSDSdir which aren't required, and we'll use TDEW in place of RH. In this 
example the datafiles are in &netcdf; format and contain the fields: TA, Tdew, WS, 
PREC, Rg, Rgdir, Rgdif, and PRESS which are translated into the &datm; internal names 
in this streams file. There is also a domain file that has the position information 
for this location. The normal assumption for &CLM1PT; mode in the &datm; is that data is 
hourly or half-hourly and as such is often enough that using the data on the nearest 
time-stamp is reasonable and as such the data is in a single streams file (see
<xref linkend="clm1pt_mode_datm_settings"></xref> for more information on 
the default settings for &datm; and how to change them. If the data is less often three to six hours -- see <xref linkend="own_force_streams"></xref> 
below, where you will need to modify the time-interpolation method as well as the 
time stamp offsets. In the example below we also have to divide the single
stream file into three files to manage the time-stamps and time interpolation
algorithm for the different types of data differently.
<example id="own_force_streams">
<title>Example of &datm; streams files with your own forcing for 3-hourly data</title>
<para>
Precipitation streams file 
(<filename>clm1PT.1x1pt_lapazMEX.precip.stream.txt</filename> file) .
</para>
<screen width="99">
&lt;streamstemplate&gt;
&lt;stream&gt;
      &lt;dataSource&gt;
         CLMNCEP
      &lt;/dataSource&gt;
      &lt;domainInfo&gt;
         &lt;variableNames&gt;
            time    time
            xc      lon
            yc      lat
            area    area
            mask    mask
         &lt;/variableNames&gt;
         &lt;filePath&gt;
            $DIN_LOC_ROOT/atm/datm7/domain.clm
         &lt;/filePath&gt;
         &lt;fileNames&gt;
            domain.lnd.1x1pt_lapazMEX_navy.nc
         &lt;/fileNames&gt;
      &lt;/domainInfo&gt;
      &lt;fieldInfo&gt;
         &lt;variableNames&gt;
            PRECTmms PREC
         &lt;/variableNames&gt;
         &lt;offset&gt;
            -5400
         &lt;/offset&gt;
         &lt;filePath&gt;
            $DIN_LOC_ROOT/atm/datm7/CLM1PT_data/1x1pt_lapazMEX
         &lt;/filePath&gt;
         &lt;fileNames&gt;
            2004-01.nc
            2004-02.nc
            2004-03.nc
.
.
.
            2009-12.nc
         &lt;/fileNames&gt;
      &lt;/fieldInfo&gt;
&lt;/stream&gt;
&lt;/streamstemplate&gt;
</screen>
<para>
Solar streams file (<filename>clm1PT.1x1pt_lapazMEX.solar.stream.txt</filename> file).
</para>
<screen width="99">
&lt;streamstemplate&gt;
&lt;stream&gt;
      &lt;dataSource&gt;
         CLMNCEP
      &lt;/dataSource&gt;
      &lt;domainInfo&gt;
         &lt;variableNames&gt;
            time    time
            xc      lon
            yc      lat
            area    area
            mask    mask
         &lt;/variableNames&gt;
         &lt;filePath&gt;
            $DIN_LOC_ROOT/atm/datm7/domain.clm
         &lt;/filePath&gt;
         &lt;fileNames&gt;
            domain.lnd.1x1pt_lapazMEX_navy.nc
         &lt;/fileNames&gt;
      &lt;/domainInfo&gt;
      &lt;fieldInfo&gt;
         &lt;variableNames&gt;
            FSDS     Rg
            FSDSdir  Rgdir
            FSDSdif  Rgdif
         &lt;/variableNames&gt;
         &lt;offset&gt;
            -10800
         &lt;/offset&gt;
         &lt;filePath&gt;
            $DIN_LOC_ROOT/atm/datm7/CLM1PT_data/1x1pt_lapazMEX
         &lt;/filePath&gt;
         &lt;fileNames&gt;
            2004-01.nc
            2004-02.nc
            2004-03.nc
.
.
.
            2009-12.nc
         &lt;/fileNames&gt;
      &lt;/fieldInfo&gt;
&lt;/stream&gt;
&lt;/streamstemplate&gt;
</screen>
<para>
Other fields streams file.
(<filename>clm1PT.1x1pt_lapazMEX.other.stream.txt</filename> file) .
</para>
<screen width="99">
&lt;streamstemplate&gt;
&lt;stream&gt;
      &lt;dataSource&gt;
         CLMNCEP
      &lt;/dataSource&gt;
      &lt;domainInfo&gt;
         &lt;variableNames&gt;
            time    time
            xc      lon
            yc      lat
            area    area
            mask    mask
         &lt;/variableNames&gt;
         &lt;filePath&gt;
            $DIN_LOC_ROOT/atm/datm7/domain.clm
         &lt;/filePath&gt;
         &lt;fileNames&gt;
            domain.lnd.1x1pt_lapazMEX_navy.nc
         &lt;/fileNames&gt;
      &lt;/domainInfo&gt;
      &lt;fieldInfo&gt;
         &lt;variableNames&gt;
            TBOT     TA
            TDEW     Tdew
            WIND     WS
            PSRF     PRESS
         &lt;/variableNames&gt;
         &lt;offset&gt;
            -5400
         &lt;/offset&gt;
         &lt;filePath&gt;
            $DIN_LOC_ROOT/atm/datm7/CLM1PT_data/1x1pt_lapazMEX
         &lt;/filePath&gt;
         &lt;fileNames&gt;
            2004-01.nc
            2004-02.nc
            2004-03.nc
.
.
.
            2009-12.nc
         &lt;/fileNames&gt;
      &lt;/fieldInfo&gt;
&lt;/stream&gt;
&lt;/streamstemplate&gt;
</screen>
<para>
Example streams namelist for the above streams files:
</para>
<screen width="99">
 &amp;shr_strdata_nml
   dataMode       = 'CLMNCEP'
   domainFile     = '$DOMAINFILE'
   streams        = 'clm1PT.1x1pt_lapazMEX.solar.stream.txt  1 2004 2009 ',
                    'clm1PT.1x1pt_lapazMEX.precip.stream.txt 1 2004 2009 ',
                    'clm1PT.1x1pt_lapazMEX.other.stream.txt  1 2004 2009 ',
                    'presaero.stream.txt 1 2000 2000'
   vectors        = 'null','null','null','null'
   mapmask        = 'nomask','nomask','nomask','nomask'
   mapalgo        = 'nn','nn','nn','nn'
   tintalgo       = 'coszen','nearest','linear','linear'
   taxmode        = 'cycle','cycle','cycle','cycle'
  /
</screen>
</example>
</para>
<note>
<para>
The example above shows the resolved namelist and streams file after &setup;
has been run.
</para>
</note>

<para>
We've outlined and given a few examples of using your own atmosphere
forcing. In the next chapter we go into the details of using &ptclmrel;.
</para>

</sect1>

</chapter>
<!-- End of single_point chapter -->
